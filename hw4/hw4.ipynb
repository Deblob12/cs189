{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Wine Classification with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from scipy.io import loadmat\n",
    "from save_csv import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_train_val_split(val_amt=0, percent=0):\n",
    "    data = loadmat(\"data.mat\")\n",
    "    total_num_ex = data[\"X\"].shape[0]\n",
    "    shuffle = np.random.permutation(total_num_ex) #shuffle before split\n",
    "    data_xtrain, data_ytrain = data[\"X\"][shuffle], \\\n",
    "    data[\"y\"][shuffle] #split\n",
    "    if not val_amt: #split by fixed number or percentage\n",
    "        val_amt = int(percent * total_num_ex)\n",
    "    data_xval, data_yval = data_xtrain[:val_amt,:], data_ytrain[:val_amt,:]\n",
    "    data_xtrain, data_ytrain = data_xtrain[val_amt:,:], data_ytrain[val_amt:,:]\n",
    "    return data_xtrain, data_ytrain, data_xval, data_yval\n",
    "\n",
    "def sigmoid(values):\n",
    "    return 1.0/(1.0+np.exp(-values))\n",
    "\n",
    "def predict(X,w):\n",
    "    predictions = np.dot((sigmoid(np.dot(X,w)) >= 0.5).astype(int))\n",
    "    results_to_csv(predictions)\n",
    "    print(\"test predictions saved\")\n",
    "\n",
    "def logres_cost_reg(X,y,w,lambd):\n",
    "    m = X.shape[0]\n",
    "    regularization = (lambd/(2*m)) * np.square(np.sum(w[1:]))\n",
    "    J = ((1/m) * (np.sum(np.dot(-y, np.log(predictions)) - np.dot(1-y, np.log(1-predictions))))) + regularization\n",
    "    print(\"cost: \" + str(J))\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_xtrain, wine_ytrain, wine_xval, wine_yval = shuffle_train_val_split(percent=0.2)\n",
    "m1, n1 = wine_xtrain.shape\n",
    "m2, n2 = wine_xval.shape\n",
    "wine_xtrain = np.concatenate([np.ones((m1, 1)), wine_xtrain], axis=1)\n",
    "wine_xval = np.concatenate([np.ones((m2, 1)), wine_xval], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 batch gradient descent update equation for logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: insert handwritten image here for derivations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.001\n",
    "lambd = 0.1 #actually lambda\n",
    "theta = np.zeros(m1+1)\n",
    "costs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchGD_reg_update(X,y,theta,lmbda):\n",
    "    unreg = -np.dot(X.T,y-sigmoid(np.dot(X,theta)))\n",
    "    reg = lmnda/len(y) * np.sum(theta)\n",
    "    gradients = unreg + reg\n",
    "    return theta\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
