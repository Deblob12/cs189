{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loaded mnist data!\n",
      "test_data (10000, 784)\n",
      "training_data (60000, 784)\n",
      "training_labels (60000, 1)\n",
      "\n",
      "loaded spam data!\n",
      "test_data (5857, 32)\n",
      "training_data (5172, 32)\n",
      "training_labels (5172, 1)\n",
      "\n",
      "loaded cifar10 data!\n",
      "test_data (10000, 3072)\n",
      "training_data (50000, 3072)\n",
      "training_labels (50000, 1)\n"
     ]
    }
   ],
   "source": [
    "#1 Python Configuration and Data Loading\n",
    "import sys\n",
    "\n",
    "if sys.version_info[0] < 3:\n",
    "    raise Exception(\"Python 3 not detected.\")\n",
    "    \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy import io\n",
    "# import pandas as pd\n",
    "\n",
    "for data_name in [\"mnist\", \"spam\", \"cifar10\"]:\n",
    "    data = io.loadmat(\"data/%s_data.mat\" % data_name)\n",
    "    print(\"\\nloaded %s data!\" % data_name)\n",
    "    fields = \"test_data\", \"training_data\", \"training_labels\"\n",
    "    for field in fields:\n",
    "        print(field, data[field].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 Data Partitioning\n",
    "np.random.seed(1)\n",
    "\n",
    "def shuffle_train_val_split(name, val_amt=0, percent=0):\n",
    "    data = io.loadmat(\"data/%s_data.mat\" % name)\n",
    "    total_num_ex = data[\"training_data\"].shape[0]\n",
    "    shuffle = np.random.permutation(total_num_ex) \n",
    "    #shuffle before split\n",
    "    data_xtrain, data_ytrain = data[\"training_data\"][shuffle], data[\"training_labels\"][shuffle]\n",
    "    #split\n",
    "    if not val_amt:\n",
    "        #spam\n",
    "        val_amt = int(percent * total_num_ex)\n",
    "    data_xval, data_yval = data_xtrain[:val_amt,:], data_ytrain[:val_amt,:]\n",
    "    data_xtrain, data_ytrain = data_xtrain[val_amt:,:], data_ytrain[val_amt:,:]\n",
    "    return data_xtrain, data_ytrain, data_xval, data_yval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 Data Partitioning\n",
    "mnist_xtrain, mnist_ytrain, mnist_xval, mnist_yval = shuffle_train_val_split(\"mnist\", 10000)\n",
    "spam_xtrain, spam_ytrain, spam_xval, spam_yval = shuffle_train_val_split(\"spam\", percent=0.2)\n",
    "cifar10_xtrain, cifar10_ytrain, cifar10_xval, cifar10_yval = shuffle_train_val_split(\"cifar10\", 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 Support Vector Machines: Coding\n",
    "\n",
    "#preprocessing\n",
    "mnist_xtrain, mnist_xval = (mnist_xtrain-np.mean(mnist_xtrain))/np.std(mnist_xtrain), (mnist_xval-np.mean(mnist_xval))/np.std(mnist_xval)\n",
    "#remember to normalize test set as well\n",
    "\n",
    "def train(data_xtrain, data_ytrain, data_xval, data_yval, num_ex, kernel):\n",
    "    data_ytrain = data_ytrain.reshape(-1,)\n",
    "    data_yval = data_yval.reshape(-1,)\n",
    "    model = svm.SVC(gamma=0.05, kernel=kernel, cache_size=2000)\n",
    "    model.fit(data_xtrain[:num_ex],data_ytrain[:num_ex])\n",
    "    return 1-accuracy_score(data_ytrain, model.predict(data_xtrain)), 1-accuracy_score(data_yval,model.predict(data_xval))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3a, MNIST\n",
    "num_exs = [100, 200, 500, 1000, 2000, 5000, 10000]\n",
    "mnist_train_err = []\n",
    "mnist_val_err = []\n",
    "for num_ex in num_exs:\n",
    "    train_err, val_err = train(mnist_xtrain, mnist_ytrain, mnist_xval, mnist_yval, num_ex, \"linear\")\n",
    "    print(train_err,val_err,num_ex)\n",
    "    mnist_train_err.append(train_err)\n",
    "    mnist_val_err.append(mnist_val_err)\n",
    "    \n",
    "plt.plot(mnist_train_err, mnist_val_err, 'ro')\n",
    "plt.axis(num_exs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.221604639922668 0.21179883945841393 100\n",
      "0.20807153214113094 0.20889748549323017 200\n",
      "0.20082165297245047 0.18471953578336553 500\n",
      "0.20372160463992262 0.17988394584139267 1000\n",
      "0.20372160463992262 0.17988394584139267 2000\n"
     ]
    }
   ],
   "source": [
    "#3b, spam\n",
    "num_exs = [100, 200, 500, 1000, 2000, spam_xtrain.shape[0]]\n",
    "spam_train_err = []\n",
    "spam_val_err = []\n",
    "for num_ex in num_exs:\n",
    "    train_err, val_err = train(spam_xtrain, spam_ytrain, spam_xval, spam_yval, num_ex, \"linear\")\n",
    "    print(train_err,val_err,num_ex)\n",
    "    spam_train_err.append(train_err)\n",
    "    spam_val_err.append(spam_val_err)\n",
    "    \n",
    "plt.plot(spam_train_err, spam_val_err, 'ro')\n",
    "plt.axis(num_exs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3c, cifar10\n",
    "num_exs = [100, 200, 500, 1000, 2000, 5000]\n",
    "cifar10_train_err = []\n",
    "cifar10_val_err = []\n",
    "for num_ex in num_exs:\n",
    "    train_err, val_err = train(cifar10_xtrain, cifar10_ytrain, cifar10_xval, cifar10_yval, num_ex, \"linear\")\n",
    "    print(train_err,val_err,num_ex)\n",
    "    cifar10_train_err.append(cifar10_err)\n",
    "    cifar10_val_err.append(cifar10_val_err)\n",
    "    \n",
    "plt.plot(cifar10_train_err, cifar10_val_err, 'ro')\n",
    "plt.axis(num_exs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 Hyperparameter Tuning\n",
    "def train_hyper(data_xtrain, data_ytrain, data_xval, data_yval, num_ex, kernel, C):\n",
    "    data_ytrain = data_ytrain.reshape(-1,)\n",
    "    data_yval = data_yval.reshape(-1,)\n",
    "    model = svm.SVC(gamma=0.001, kernel=kernel, C=C)\n",
    "    model.fit(data_xtrain[:num_ex],data_ytrain[:num_ex])\n",
    "    return 1-accuracy_score(data_yval,model.predict(data_xval))\n",
    "\n",
    "num_ex = 10000\n",
    "C = [0, 0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 1]\n",
    "mnist_val_err = []\n",
    "for c in C:\n",
    "    val_err = train_hyper(mnist_xtrain, mnist_ytrain, mnist_xval, mnist_yval, num_ex, \"linear\", c)\n",
    "    print(val_err,c)\n",
    "    mnist_val_err.append(mnist_val_err)\n",
    "print(\"best C value is \", C[mnist_val_err.index(min(mnist_val_err))])\n",
    "plt.plot(mnist_val_err, 'ro')\n",
    "plt.axis(C)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
